{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cv2\n",
    "#print(cv2.getBuildInformation())\n",
    "#import serial.tools.list_ports\n",
    "\n",
    "\n",
    "class ArdData:\n",
    "    def __init__(self):\n",
    "        #self.address = ('/dev/ttyACM0')\n",
    "        #self.arData = serial.Serial(self.address, 9600)\n",
    "        self.apa = \" Corte Activado\"\n",
    "        self.enc = \"Corte Desactivado\"\n",
    "\n",
    "    def cut_on(self):\n",
    "        #self.arData.write(\"1\\n\")\n",
    "        print(self.apa)\n",
    "        \n",
    "    def cut_off(self):\n",
    "        #self.arData.write(\"2\\n\")\n",
    "        print(self.enc)\n",
    "        \n",
    "    \n",
    "        #self.arData = ArdData()\n",
    "        #time.sleep(2)\n",
    "\n",
    "        #self.arData.line_off()\n",
    "        #time.sleep(0.5)\n",
    "        #self.arData.line_on()\n",
    "        #time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import time\n",
    "\n",
    "class mySQL():\n",
    "    def __init__(self):\n",
    "        self.mydb = mysql.connector.connect(\n",
    "                    host=\"localhost\",\n",
    "                    user=\"vision\",\n",
    "                    passwd=\"Horus2014\",\n",
    "                    database=\"fm\",\n",
    "                    auth_plugin=\"mysql_native_password\")\n",
    "        self.mycursor = self.mydb.cursor()\n",
    "        print(self.mydb)\n",
    "        \n",
    "        \n",
    "    def saveEvent(self, cam, ): \n",
    "        seconds = time.time()\n",
    "        sql = \"INSERT INTO events (Time, Camara) VALUES (%s, %s)\"\n",
    "        val = (seconds, cam)\n",
    "        self.mycursor.execute(sql, val)\n",
    "        self.mydb.commit()\n",
    "        print(self.mycursor.rowcount, \"record inserted.\")\n",
    "        print(\"Seconds since epoch =\", seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds since epoch = 1568844511.8746405\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "seconds = time.time()\n",
    "print(\"Seconds since epoch =\", seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0918 17:08:40.670683 15288 deprecation.py:323] From C:\\Users\\HORUS\\Notebooks\\ObjectDetection\\darkflow\\darkflow\\net\\build.py:81: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading from .pb and .meta\n",
      "GPU mode with 0.7 usage\n"
     ]
    }
   ],
   "source": [
    "from PyQt5.QtCore import QThread, pyqtSignal, Qt, QElapsedTimer\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QPushButton, QMessageBox\n",
    "from darkflow.net.build import TFNet\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "#options = { \"pbLoad\": 'built_graph/yolov2W2C.pb' ,           \n",
    "#            \"metaLoad\": 'built_graph/yolov2W2C.meta' ,\n",
    "#            \"gpu\": 0.8}\n",
    "#USING TINY WEIGHTS\n",
    "options = { \"pbLoad\": 'built_graph/yolov2-tiny400.pb' ,           \n",
    "            \"metaLoad\": 'built_graph/yolov2-tiny400.meta' ,\n",
    "            \"gpu\": 0.7}\n",
    "\n",
    "\n",
    "\n",
    "tfnet2 = TFNet(options) \n",
    "\n",
    "\n",
    "url1 = \"./sample_video/Video2.mp4\"\n",
    "#url1 = \"rtsp://admin:admin@192.168.88.101/stream1\"\n",
    "#url2 = \"rtsp://admin:admin@192.168.50.150:554/cam/realmonitor?channel=1&subtype=1\"\n",
    "url2= \"./sample_video/Video3.mp4\" \n",
    "#url2 = \"rtsp://admin:admin@192.168.88.102/stream1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection.MySQLConnection object at 0x000002B32A9DE550>\n",
      "Corte Desactivado\n",
      " Corte Activado\n",
      "1 record inserted.\n",
      "Seconds since epoch = 1568844536.8064206\n",
      "Corte Desactivado\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HORUS\\Miniconda3\\envs\\tf_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "class App(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title = 'FMVISION'\n",
    "        self.left = 100\n",
    "        self.top = 100\n",
    "        self.width = 640\n",
    "        self.height = 480\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle(self.title)\n",
    "        self.setGeometry(self.left, self.top, self.width, self.height)\n",
    "        self.resize(1600, 1200)\n",
    "        # create a Button\n",
    "        \n",
    "        btnByPass = QPushButton(self)\n",
    "        btnByPass.move(750, 620)  \n",
    "        btnByPass.setText(\"BYPASS\")\n",
    "        btnByPass.setCheckable(True)\n",
    "        btnByPass.clicked[bool].connect(self.setColor)        \n",
    "              \n",
    "        \n",
    "        self.arData = ArdData() #Iniciamos la clase de AR\n",
    "        self.mysql = mySQL() #iniciar clase para guardar eventos\n",
    "        time.sleep(2)\n",
    "        self.arData.cut_off() #Desactivamos el corte\n",
    "        #btnByPass.clicked.connect(self.stopTop) #ESTE BOTON ESTA en el mainWindow y activa directamente\n",
    "        \n",
    "        # CAMARA TOP INTERFACE\n",
    "        lbcamTop = QLabel(self)\n",
    "        lbcamTop.move(106, 120)\n",
    "        lbcamTop.resize(640, 480)\n",
    "        \n",
    "        labelTopCount = QLabel(self)\n",
    "        labelTopCount.move(420, 100)\n",
    "        labelTopCount.setText(\"BLOBS\") \n",
    "        \n",
    "        btnCapTop = QPushButton(self)\n",
    "        btnCapTop.move(400, 620)  \n",
    "        btnCapTop.setText(\"Capture\")\n",
    "        btnCapTop.clicked.connect(self.captureTop)\n",
    "        \n",
    "        self.th = Thread(self) #inicia Constructor\n",
    "        self.th.changePixmap.connect(lbcamTop.setPixmap)\n",
    "        self.th.changeLabel.connect(labelTopCount.setText)\n",
    "        #self.th.blobDetected.connect(self.arData.cut_on)\n",
    "        self.th.blobDetected.connect(self.show_dialog)\n",
    "        self.th.start() #Inicia el thread\n",
    "        \n",
    "        # CAMARA BOT INTERFACE\n",
    "        lbcamBot = QLabel(self)\n",
    "        lbcamBot.move(852, 120)\n",
    "        lbcamBot.resize(640, 480)\n",
    "        \n",
    "        btnCapBot = QPushButton(self)\n",
    "        btnCapBot.move(1170, 620)  \n",
    "        btnCapBot.setText(\"Capture\")\n",
    "        btnCapBot.clicked.connect(self.captureBot)\n",
    "        \n",
    "        labelBotCount = QLabel(self)\n",
    "        labelBotCount.move(1172, 100)\n",
    "        labelBotCount.setText(\"BLOBS\")                    \n",
    "        \n",
    "        self.thBot = ThreadBot(self)\n",
    "        self.thBot.changePixmap.connect(lbcamBot.setPixmap)\n",
    "        self.thBot.changeLabel.connect(labelBotCount.setText)\n",
    "        self.thBot.start()        \n",
    "        \n",
    "        \n",
    "    def setColor(self, pressed):\n",
    "        \n",
    "        source = self.sender()\n",
    "        \n",
    "        if pressed:            \n",
    "            self.arData.cut_off()\n",
    "            self.th.bypass = 1            \n",
    "        else: \n",
    "            self.arData.cut_on()\n",
    "            self.th.bypass = 0\n",
    "        \n",
    "    def show_dialog(self):\n",
    "        self.arData.cut_on()\n",
    "        self.mysql.saveEvent(\"Superior\")\n",
    "        QMessageBox.about(self, \"Alerta\", \"Se ha detectado un poro\")\n",
    "        self.arData.cut_off()\n",
    "        self.th.bypass = 0\n",
    "            \n",
    "    def captureTop(self):\n",
    "        #print(\"HELLO\")        \n",
    "        self.th.captureImg()\n",
    "    def captureBot(self):\n",
    "        #print(\"HELLO\")\n",
    "        self.thBot.captureImg()        \n",
    "\n",
    "    def closeEvent(self, event):\n",
    "        self.th.stop()\n",
    "        self.thBot.stop()\n",
    "        QWidget.closeEvent(self, event)\n",
    "\n",
    "#class Dialog(QDialog):\n",
    "   # def __init__(self, *args, **kwargs):\n",
    "      #  super(Dialog, self).__init__(*args, **kwargs)\n",
    "       # self.setWindowTitle(\"Soy un popup\")\n",
    "       # self.setFixedSize(200, 100)\n",
    "          \n",
    "        \n",
    "class MyVideoCapture: #ESTA CLASE CAPTURA LOS FOTOGRAMAS\n",
    "    def __init__(self, video_source):\n",
    "        # Open the video source\n",
    "        self.vid = cv2.VideoCapture(video_source)       \n",
    "        #self.vid.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "        if not self.vid.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source)\n",
    "\n",
    "        # Get video source width and height\n",
    "        self.width = int(self.vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.height = int(self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "       # print(self.width)\n",
    "\n",
    "    def get_frame(self):\n",
    "        if self.vid.isOpened():\n",
    "            ret, frame = self.vid.read()\n",
    "            if ret:\n",
    "                # Return a boolean success flag and the current frame converted to BGR\n",
    "                return (ret, frame)\n",
    "\n",
    "            else:\n",
    "                return (ret, None)\n",
    "        else:\n",
    "            return (ret, None)\n",
    "\n",
    "    # Release the video source when the object is destroyed\n",
    "    def __del__(self):\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()            \n",
    "            \n",
    "class boxing: #ESTA CLASE ENCIERRA EN CIRCULOS Y BUSCA COINCIDENCIA ENTRE DOS LINEAS\n",
    "    def __init__(self, CoorYEntranceLine, CoorYExitLine):        \n",
    "        self.CoorYEntranceLine = CoorYEntranceLine\n",
    "        self.CoorYExitLine = CoorYExitLine        \n",
    "    \n",
    "    def getbox(self, original_img , predictions,):\n",
    "        self.original_img = original_img\n",
    "        self.predictions = predictions\n",
    "        self.newImage = np.copy(self.original_img)\n",
    "        self.AbsDistance = 0\n",
    "        for result in self.predictions:\n",
    "            top_x = result['topleft']['x']\n",
    "            top_y = result['topleft']['y']\n",
    "\n",
    "            btm_x = result['bottomright']['x']\n",
    "            btm_y = result['bottomright']['y']\n",
    "            \n",
    "            self.CoordXCentroid = (btm_x-top_x)/2+top_x\n",
    "            self.CoordYCentroid = (btm_y-top_y)/2+top_y\n",
    "\n",
    "            confidence = result['confidence']\n",
    "            label = result['label'] + \" \" + str(round(confidence, 3))\n",
    "\n",
    "            if confidence > 0.6:\n",
    "                self.newImage = cv2.rectangle(self.newImage, (top_x, top_y), (btm_x, btm_y), (255,0,0), 3)\n",
    "                self.newImage = cv2.putText(self.newImage, label, (top_x, top_y-5), cv2.FONT_HERSHEY_COMPLEX_SMALL , 2.0, (0, 230, 0), 1, cv2.LINE_AA)\n",
    "                #find object's centroid               \n",
    "                self.ObjectCentroid = (int(self.CoordXCentroid),int(self.CoordYCentroid))\n",
    "                self.newImage = cv2.circle(self.newImage, self.ObjectCentroid, 1, (255, 0, 0), 3)                                  \n",
    "                self.AbsDistance = (self.CoordYCentroid - self.CoorYEntranceLine)\n",
    "                \n",
    "        if ((self.AbsDistance >= 1) and (self.CoordYCentroid < self.CoorYExitLine)):                   \n",
    "            return self.newImage, 1\n",
    "        else:\n",
    "            return self.newImage, 0\n",
    "        \n",
    "class Thread(QThread): #ESTA CLASE INICIA UN THREAD PARA UNA CAMARA\n",
    "    changePixmap = pyqtSignal(QPixmap)\n",
    "    changeLabel = pyqtSignal(str) \n",
    "    blobDetected = pyqtSignal()\n",
    "\n",
    "    def __init__(self, parent=None):\n",
    "        QThread.__init__(self, parent=parent)\n",
    "        self.isRunning = True\n",
    "        self.OffsetRefLines = 50 #Distancia entre lineas de captura\n",
    "        #self.vid = MyVideoCapture(\"rtspsrc location=\"+url1+\" latency=20 ! decodebin ! videoconvert ! appsink max-buffers=1 drop=true\")\n",
    "        self.vid = MyVideoCapture(url1) #Iniciar Clase de captura        \n",
    "        self.savenum = 0\n",
    "        self.bypass = 0\n",
    "\n",
    "    def run(self):\n",
    "        height = self.vid.height #Obtine altura del fotograma\n",
    "        width = self.vid.width #Obtiene ancho del fotograma\n",
    "        #plot reference lines (entrance and exit lines) \n",
    "        CoorYEntranceLine = (height / 2)+200-self.OffsetRefLines   #Encuentra coordenadas de la primera linea\n",
    "        CoorYExitLine = (height / 2)+200+self.OffsetRefLines #Encuentra coordenadas de la segunda linea\n",
    "        new_boxing = boxing(CoorYEntranceLine, CoorYExitLine)  #Inicia la clase de boxing con las lineas      \n",
    "\n",
    "        while self.isRunning:\n",
    "            ret, self.frame = self.vid.get_frame()\n",
    "            rgbImage = cv2.cvtColor(self.frame, cv2.COLOR_BGR2RGB) #convertimos a RGB compatible con Pixmap\n",
    "            #DIBUJAMOS LAS LINEAS DELIMITADORAS\n",
    "            rgbImage = cv2.line(rgbImage, (0,int(CoorYEntranceLine)), (width,int(CoorYEntranceLine)), (255, 0, 0), 2)\n",
    "            rgbImage = cv2.line(rgbImage, (0,int(CoorYExitLine)), (width,int(CoorYExitLine)), (0, 0, 255), 2)                      \n",
    "            results = tfnet2.return_predict(self.frame) #Predecimos los objetos en un fotograma original              \n",
    "            rgbImage, rx = new_boxing.getbox(rgbImage, results) #Dibujamos los cuadros en objetos y checamos si pasa\n",
    "            if (rx and self.bypass != 1): #rx contine 1 si hubo coincidencia entre el centroid y las lineas de limitadoras\n",
    "                self.changeLabel.emit(str(\"PORO\")) \n",
    "                self.blobDetected.emit()\n",
    "                self.bypass = 1\n",
    "            else: #Manda 0 si no hay coincidencia pero aun asi manda el fotograma con los cuadros\n",
    "                self.changeLabel.emit(str(\"0\"))             \n",
    "            convertToQtFormat = QImage(rgbImage.data, rgbImage.shape[1], rgbImage.shape[0], QImage.Format_RGB888)\n",
    "            convertToQtFormat = QPixmap.fromImage(convertToQtFormat)\n",
    "            p = convertToQtFormat.scaled(640, 480, Qt.KeepAspectRatio)\n",
    "            self.changePixmap.emit(p) #Esto hace la conexion entre el multithread y el programa principal\n",
    "            #now = datetime.datetime.now()\n",
    "            #sec = now.second               \n",
    "            \n",
    "    def captureImg(self):        \n",
    "        cv2.imwrite('./sample_img/poros/recu'+str(self.savenum)+'.jpg', self.frame)\n",
    "        cv2.imshow(\"Captured\", self.frame)\n",
    "        self.savenum += 1\n",
    "\n",
    "    def stop(self):\n",
    "        self.isRunning = False\n",
    "        self.quit()\n",
    "        self.wait()\n",
    "\n",
    "        \n",
    "class ThreadBot(QThread): #ESTA CLASE INICIA UN THREAD PARA LA OTRA CAMARA\n",
    "    changePixmap = pyqtSignal(QPixmap)\n",
    "    changeLabel = pyqtSignal(str) \n",
    "    \n",
    "\n",
    "    def __init__(self, parent=None):\n",
    "        QThread.__init__(self, parent=parent)\n",
    "        self.isRunning = True      \n",
    "        #self.vid = MyVideoCapture(\"rtspsrc location=\"+url2+\" latency=20 ! decodebin ! videoconvert ! appsink max-buffers=1 drop=true\")\n",
    "        self.vid = MyVideoCapture(url2)\n",
    "        self.detector = cv2.SimpleBlobDetector_create()\n",
    "        self.savenum = 0\n",
    "        \n",
    "        \n",
    "    def run(self):\n",
    "             \n",
    "        while self.isRunning:       \n",
    "            \n",
    "            \n",
    "            ret, self.frame = self.vid.get_frame()\n",
    "            grayImage = cv2.cvtColor(self.frame, cv2.COLOR_BGR2GRAY)            \n",
    "            #cv2.imshow(\"Keypoints\", grayImage)\n",
    "            keypoints = self.detector.detect(grayImage)\n",
    "            im_with_keypoints = cv2.drawKeypoints(self.frame, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "            rgbImage = cv2.cvtColor(im_with_keypoints, cv2.COLOR_BGR2RGB)\n",
    "            convertToQtFormat = QImage(rgbImage.data, rgbImage.shape[1], rgbImage.shape[0], QImage.Format_RGB888)\n",
    "            convertToQtFormat = QPixmap.fromImage(convertToQtFormat)\n",
    "            p = convertToQtFormat.scaled(640, 480, Qt.KeepAspectRatio)\n",
    "            self.changePixmap.emit(p)\n",
    "            self.changeLabel.emit(str(len(keypoints))) \n",
    "        \n",
    "    def captureImg(self):        \n",
    "        cv2.imwrite('./sample_img/poros/ace'+str(self.savenum)+'.jpg', self.frame)\n",
    "        cv2.imshow(\"Captured\", self.frame)\n",
    "        self.savenum += 1      \n",
    "\n",
    "\n",
    "    def stop(self):\n",
    "        self.isRunning = False\n",
    "        self.quit()\n",
    "        self.wait()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    ex = App()\n",
    "    ex.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
